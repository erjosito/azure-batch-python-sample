{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Batch Python Notebook\n",
    "\n",
    "This is is a sample Jupyter Notebook containing some code to manage Azure Batch container-based pools with the Python SDK. Some of the code is taken from the samples in the Github repo below.\n",
    "\n",
    "It demonstrates these concepts, amongst others:\n",
    "\n",
    "* How to create a container-enabled pool, including startup tasks\n",
    "* How to access the state of compute nodes inside of a pool\n",
    "* How to launch container-based tasks, with or without a custom CMD, with the default WD or with another one\n",
    "* How to delete tasks, jobs and pools\n",
    "\n",
    "See these links for further information:\n",
    "\n",
    "* https://docs.microsoft.com/en-us/azure/batch/batch-account-create-portal: How-To Azure Batch documentation in docs.microsoft.com\n",
    "* https://docs.microsoft.com/en-us/python/api/azure-batch/azure.batch?view=azure-python: Azure Batch Python SDK reference\n",
    "* https://github.com/Azure/azure-batch-samples/tree/master/Python/Batch: Azure Batch Python samples, where this notebook is based from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import io\n",
    "import azure.storage.blob as azureblob\n",
    "import azure.batch.batch_service_client as batch\n",
    "import azure.batch.batch_auth as batchauth\n",
    "import azure.batch.models as batchmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the configuration\n",
    "batch_account_key = 'one of your two batch account keys'\n",
    "batch_account_name = 'yourbatchaccount'\n",
    "batch_service_url = 'https://yourbatchaccount.westeurope.batch.azure.com'\n",
    "\n",
    "storage_account_key = 'one of your two storage account keys'\n",
    "storage_account_name = 'yourstorageaccount'       # Not the FQDN, just the account name\n",
    "storage_account_suffix = 'core.windows.net'\n",
    "blobfuse_container_mount = 'mountdrive'\n",
    "blobfuse_connection_filename = 'connection.cfg'  # Needs to match the one in compute_node_init.sh\n",
    "should_delete_container = False\n",
    "should_delete_job = False\n",
    "should_delete_pool = False\n",
    "pool_vm_size = \"STANDARD_D1_V2\"\n",
    "pool_vm_count = 1\n",
    "vm_publisher = 'microsoft-azure-batch'\n",
    "vm_offer = 'ubuntu-server-container'\n",
    "vm_sku = '16-04-lts'\n",
    "os_username = \"batchuser\"\n",
    "os_password = \"yoursecretpassword123!\"\n",
    "\n",
    "batch_pool_name = \"mycomputepool\"\n",
    "batch_job_name = \"myJob\"\n",
    "batch_task_name = \"myDockerTask\"\n",
    "batch_bash_task_name = \"myBashTask\"\n",
    "\n",
    "startup_blob_container_name = \"startup\"\n",
    "compute_node_init = \"compute_node_init.sh\"\n",
    "compute_node_init_path = \"./\" + compute_node_init\n",
    "docker_run_command = \"docker run\"\n",
    "stdout_filename = \"stdout.txt\"\n",
    "stderr_filename = \"stderr.txt\"\n",
    "\n",
    "task_blob_container_name = \"task\"\n",
    "task_file_to_upload = \"hellotask.txt\"\n",
    "task_file_to_upload_path = \"./hellotask.txt\"\n",
    "\n",
    "acr_name = \"youracrname\"\n",
    "acr_url = acr_name + \".azurecr.io\"\n",
    "acr_username = \"youracrusername\"\n",
    "acr_password = \"youracrpassword\"\n",
    "acr_image = \"yourcontainerimage:1.0\"\n",
    "docker_image_name = acr_url + \"/\" + acr_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pool creation\n",
    "\n",
    "These cells contain functions relevant to creating a container-enabled pool\n",
    "\n",
    "* `wrap_commands_in_shell` is used for the startup task, to serialize multiple commands (it is used for standard tasks as well)\n",
    "* `create_container_pool` defines a pool object with a containerConfig, and it gives it to `create_pool_if_not_exist`\n",
    "* `create_pool_if_not_exist` calls the method batch_client.pool.add\n",
    "* For the startup task a startup file is uploaded to a blob container with a new SAS. `create_container_pool` calls these functions that help with the Azure Storage API: `upload_blob_and_create_sas` and `create_sas_token`\n",
    "* `select_latest_verified_vm_image_with_node_agent_sku` helps by providing the latest image supported by Azure Batch corresponding to a certain Publisher, Offer and SKU prefix combination\n",
    "* `wait_for_pool_to_complete` periodically checks the newly provisioned pool until the nodes are ready\n",
    "* `print_pool_info` prints some details about the pool, once it is ready\n",
    "* `wait_for_pool_to_be_deleted` periodically checks a certain pool until it no longer exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts a list of bash commands into a single string that can be used as command for\n",
    "#   a container/bash task\n",
    "def wrap_commands_in_shell(ostype, commands):\n",
    "    \"\"\"Wrap commands in a shell\n",
    "    :param list commands: list of commands to wrap\n",
    "    :param str ostype: OS type, linux or windows\n",
    "    :rtype: str\n",
    "    :return: a shell wrapping commands\n",
    "    \"\"\"\n",
    "    if ostype.lower() == 'linux':\n",
    "        return '/bin/bash -c \\'set -e; set -o pipefail; {}; wait\\''.format(\n",
    "            ';'.join(commands))\n",
    "    elif ostype.lower() == 'windows':\n",
    "        return 'cmd.exe /c \"{}\"'.format('&'.join(commands))\n",
    "    else:\n",
    "        raise ValueError('unknown ostype: {}'.format(ostype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blob container and batch pool with a container configuration, including a startup task\n",
    "def create_container_pool(batch_client, block_blob_client, pool_id, vm_size, vm_count):\n",
    "    \"\"\"Creates an Azure Batch pool with the specified id.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param block_blob_client: The storage block blob client to use.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str pool_id: The id of the pool to create.\n",
    "    :param str vm_size: vm size (sku)\n",
    "    :param int vm_count: number of vms to allocate\n",
    "    \"\"\"\n",
    "    # pick the latest supported sku for UbuntuServer\n",
    "    sku_to_use, image_ref_to_use = \\\n",
    "        select_latest_verified_vm_image_with_node_agent_sku(\n",
    "            batch_client, vm_publisher, vm_offer, vm_sku)\n",
    "    print(\"Selected reference image:\", image_ref_to_use)\n",
    "    \n",
    "    # Create new blob container in Azure Storage with a SAS\n",
    "    print('Creating blob container', startup_blob_container_name, 'and uploading file', compute_node_init)\n",
    "    block_blob_client.create_container(startup_blob_container_name, fail_on_exist=False)\n",
    "    if os.path.exists(compute_node_init_path):\n",
    "        print('Uploading file', compute_node_init_path)\n",
    "        sas_url = upload_blob_and_create_sas(\n",
    "            block_blob_client,\n",
    "            startup_blob_container_name,\n",
    "            compute_node_init,\n",
    "            compute_node_init_path,\n",
    "            datetime.datetime.utcnow() + datetime.timedelta(hours=1))\n",
    "    else:\n",
    "        print(file_to_upload_path, 'could not be found!!')\n",
    "\n",
    "    # Create batch pool with a container configuration and a startup task\n",
    "    print('Defining image', docker_image_name, 'to be loaded from registry', acr_url)\n",
    "    registry_conf = batch.models.ContainerRegistry(registry_server=acr_url,\n",
    "                                                   user_name=acr_username,\n",
    "                                                   password=acr_password)\n",
    "    # This configuration defines the private registry and configures docker images to be pre-fetched\n",
    "    linux_container_conf = batch.models.ContainerConfiguration(container_image_names=[docker_image_name], \n",
    "                                                               container_registries=[registry_conf])\n",
    "    vmuser = batch.models.UserAccount(name=os_username, password=os_password, elevation_level='admin')\n",
    "    # Env variables to be loaded to the init task\n",
    "    env_storage_account = batch.models.EnvironmentSetting(\"AZURE_STORAGE_ACCOUNT\", value=storage_account_name)\n",
    "    env_storage_key = batch.models.EnvironmentSetting(\"AZURE_STORAGE_ACCESS_KEY\", value=storage_account_key)\n",
    "    env_test = batch.models.EnvironmentSetting(\"HELLO_WORLD\", value='hello world!')\n",
    "    # Command list to pass to the init task\n",
    "    blobfuse_connection_path ='./' + blobfuse_connection_filename\n",
    "    command_list=['cd $AZ_BATCH_TASK_WORKING_DIR',\n",
    "                  #'export AZURE_STORAGE_ACCOUNT='+storage_account_name,\n",
    "                  #'export AZURE_STORAGE_ACCESS_KEY='+storage_account_key,\n",
    "                  'echo \"accountName {0}\" >{1}'.format(storage_account_name, blobfuse_connection_path),\n",
    "                  'echo \"accountKey {0}\" >>{1}'.format(storage_account_key, blobfuse_connection_path),\n",
    "                  'echo \"containerName {0}\" >>{1}'.format(blobfuse_container_mount, blobfuse_connection_path),\n",
    "                  'chmod 600 ' + blobfuse_connection_path,\n",
    "                  'whoami >./whoami.txt',\n",
    "                  'printenv >./printenv.txt',\n",
    "                  'chmod 755 ./' + compute_node_init,\n",
    "                  'sudo ./' + compute_node_init]\n",
    "    # User with elevated access (to be used in the startup task, required for sudo)\n",
    "    user = batchmodels.UserIdentity(\n",
    "        auto_user=batchmodels.AutoUserSpecification(\n",
    "        elevation_level=batchmodels.ElevationLevel.admin,\n",
    "        scope=batchmodels.AutoUserScope.task))\n",
    "    # pool definition\n",
    "    pool = batchmodels.PoolAddParameter(\n",
    "        id=pool_id,\n",
    "        virtual_machine_configuration=batchmodels.VirtualMachineConfiguration(\n",
    "            image_reference=image_ref_to_use,\n",
    "            container_configuration=linux_container_conf,\n",
    "            node_agent_sku_id=sku_to_use),\n",
    "        vm_size=vm_size,\n",
    "        user_accounts=[vmuser],\n",
    "        target_dedicated_nodes=vm_count,\n",
    "        # Defines an init task\n",
    "        start_task=batchmodels.StartTask(\n",
    "            command_line=wrap_commands_in_shell('linux', command_list),\n",
    "            environment_settings=[env_storage_account, env_storage_key],\n",
    "            user_identity=user,\n",
    "            resource_files=[batchmodels.ResourceFile(file_path=compute_node_init, blob_source=sas_url)]))\n",
    "    create_pool_if_not_exist(batch_client, pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload file to blob storage and create SAS \n",
    "def upload_blob_and_create_sas(\n",
    "        block_blob_client, container_name, blob_name, file_name, expiry,\n",
    "        timeout=None):\n",
    "    \"\"\"Uploads a file from local disk to Azure Storage and creates\n",
    "    a SAS for it.\n",
    "    :param block_blob_client: The storage block blob client to use.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the container to upload the blob to.\n",
    "    :param str blob_name: The name of the blob to upload the local file to.\n",
    "    :param str file_name: The name of the local file to upload.\n",
    "    :param expiry: The SAS expiry time.\n",
    "    :type expiry: `datetime.datetime`\n",
    "    :param int timeout: timeout in minutes from now for expiry,\n",
    "        will only be used if expiry is not specified\n",
    "    :return: A SAS URL to the blob with the specified expiry time.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    block_blob_client.create_container(\n",
    "        container_name,\n",
    "        fail_on_exist=False)\n",
    "\n",
    "    block_blob_client.create_blob_from_path(\n",
    "        container_name,\n",
    "        blob_name,\n",
    "        file_name)\n",
    "\n",
    "    sas_token = create_sas_token(\n",
    "        block_blob_client,\n",
    "        container_name,\n",
    "        blob_name,\n",
    "        permission=azureblob.BlobPermissions.READ,\n",
    "        expiry=expiry,\n",
    "        timeout=timeout)\n",
    "\n",
    "    sas_url = block_blob_client.make_blob_url(\n",
    "        container_name,\n",
    "        blob_name,\n",
    "        sas_token=sas_token)\n",
    "\n",
    "    return sas_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SAS for a storage blob\n",
    "def create_sas_token(\n",
    "        block_blob_client, container_name, blob_name, permission, expiry=None,\n",
    "        timeout=None):\n",
    "    \"\"\"Create a blob sas token\n",
    "    :param block_blob_client: The storage block blob client to use.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the container to upload the blob to.\n",
    "    :param str blob_name: The name of the blob to upload the local file to.\n",
    "    :param expiry: The SAS expiry time.\n",
    "    :type expiry: `datetime.datetime`\n",
    "    :param int timeout: timeout in minutes from now for expiry,\n",
    "        will only be used if expiry is not specified\n",
    "    :return: A SAS token\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if expiry is None:\n",
    "        if timeout is None:\n",
    "            timeout = 30\n",
    "        expiry = datetime.datetime.utcnow() + datetime.timedelta(\n",
    "            minutes=timeout)\n",
    "    return block_blob_client.generate_blob_shared_access_signature(\n",
    "        container_name, blob_name, permission=permission, expiry=expiry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a valid VM SKU provided by the Azure Batch API\n",
    "def select_latest_verified_vm_image_with_node_agent_sku(\n",
    "        batch_client, publisher, offer, sku_starts_with):\n",
    "    \"\"\"Select the latest verified image that Azure Batch supports given\n",
    "    a publisher, offer and sku (starts with filter).\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param str publisher: vm image publisher\n",
    "    :param str offer: vm image offer\n",
    "    :param str sku_starts_with: vm sku starts with filter\n",
    "    :rtype: tuple\n",
    "    :return: (node agent sku id to use, vm image ref to use)\n",
    "    \"\"\"\n",
    "    # get verified vm image list and node agent sku ids from service\n",
    "    node_agent_skus = batch_client.account.list_node_agent_skus()\n",
    "    # pick the latest supported sku\n",
    "    skus_to_use = [\n",
    "        (sku, image_ref) for sku in node_agent_skus for image_ref in sorted(\n",
    "            sku.verified_image_references, key=lambda item: item.sku)\n",
    "        if image_ref.publisher.lower() == publisher.lower() and\n",
    "        image_ref.offer.lower() == offer.lower() and\n",
    "        image_ref.sku.startswith(sku_starts_with)\n",
    "    ]\n",
    "    # skus are listed in reverse order, pick first for latest\n",
    "    if len(skus_to_use)>0:\n",
    "        sku_to_use, image_ref_to_use = skus_to_use[0]\n",
    "        return (sku_to_use.id, image_ref_to_use)\n",
    "    else:\n",
    "        print(\"No SKUs matching the OS image:\", publisher, offer, sku_starts_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch pool using an existing batch client\n",
    "def create_pool_if_not_exist(batch_client, pool):\n",
    "    \"\"\"Creates the specified pool if it doesn't already exist\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param pool: The pool to create.\n",
    "    :type pool: `batchserviceclient.models.PoolAddParameter`\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Attempting to create pool:\", pool.id)\n",
    "        batch_client.pool.add(pool)\n",
    "        print(\"Created pool:\", pool.id)\n",
    "    except batchmodels.BatchErrorException as e:\n",
    "        if e.error.code != \"PoolExists\":\n",
    "            raise\n",
    "        else:\n",
    "            print(\"Pool {!r} already exists\".format(pool.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print pool info\n",
    "def print_pool_info(pool_id):\n",
    "    mypool = batch_client.pool.get(pool_id=pool_id)\n",
    "    print('Some info about pool {0}:'.format(pool_id))\n",
    "    print('- Images to download:', mypool.virtual_machine_configuration.container_configuration.container_image_names)\n",
    "    print('- Container registry:', mypool.virtual_machine_configuration.container_configuration.container_registries[0].registry_server)\n",
    "    print('- Container username:', mypool.virtual_machine_configuration.container_configuration.container_registries[0].user_name)\n",
    "    print('- Container password:', mypool.virtual_machine_configuration.container_configuration.container_registries[0].password)\n",
    "    print('- Pool nodes:', mypool.current_dedicated_nodes)\n",
    "    if mypool.current_dedicated_nodes>0:\n",
    "        nodes = batch_client.compute_node.list(pool_id, raw=False)\n",
    "        for node in nodes:\n",
    "            #print(node)    # Debug, uncomment to see the full object\n",
    "            print('  *', node.id, 'is', node.state)\n",
    "            if node.state == batchmodels.ComputeNodeState.idle:\n",
    "                print('    Start task \"{0}\" -> Status: {1}, {2}'.format(node.start_task.command_line,node.start_task_info.state, node.start_task_info.result))\n",
    "                if node.start_task_info.result == batchmodels.TaskExecutionResult.failure:\n",
    "                    print('      Start task failure info: {0}, {1}, {2}, {3}'.format(node.start_task_info.failure_info.category,\n",
    "                                                                                      node.start_task_info.failure_info.code,\n",
    "                                                                                      node.start_task_info.failure_info.message,\n",
    "                                                                                      node.start_task_info.failure_info.details))\n",
    "                print('Startup task output:')\n",
    "                print_startup_task_output(batch_client, node.id)\n",
    "                node_connection = batch_client.compute_node.get_remote_login_settings(pool_id=pool_id, node_id=node.id)\n",
    "                print('    Connection: \"ssh {0}@{1} -p {2}\"'.format(os_username, node_connection.remote_login_ip_address, node_connection.remote_login_port))\n",
    "            if node.errors:\n",
    "                for error in node.errors:\n",
    "                    print('    Error:', error.code, '-', error.message)\n",
    "            else:\n",
    "                print('    No errors :)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waits until the compute nodes in the pool are idle/unusable/failed\n",
    "def wait_for_pool_to_complete(batch_client, pool_id, timeout):\n",
    "    \"\"\"Waits for nodes in a pool to be operational.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param str job_id: The id of the job to monitor.\n",
    "    :param timeout: The maximum amount of time to wait.\n",
    "    :type timeout: `datetime.timedelta`\n",
    "    \"\"\"\n",
    "    time_to_timeout_at = datetime.datetime.now() + timeout\n",
    "\n",
    "    while datetime.datetime.now() < time_to_timeout_at:\n",
    "        mypool = batch_client.pool.get(pool_id=pool_id)\n",
    "        print(\"Pool\", pool_id, \"has\", mypool.current_dedicated_nodes, \"current dedicated nodes\")\n",
    "        if mypool.current_dedicated_nodes>0:\n",
    "            nodes = batch_client.compute_node.list(pool_id, raw=False)\n",
    "            starting_nodes=0\n",
    "            running_nodes=0\n",
    "            waiting_nodes=0\n",
    "            failed_nodes=0\n",
    "            idle_nodes=0\n",
    "            unusable_nodes=0\n",
    "            for node in nodes:\n",
    "                if node.state==batchmodels.ComputeNodeState.starting:\n",
    "                    starting_nodes+=1\n",
    "                elif node.state==batchmodels.ComputeNodeState.running:\n",
    "                    running_nodes+=1\n",
    "                elif node.state==batchmodels.ComputeNodeState.waiting_for_start_task:\n",
    "                    waiting_nodes+=1\n",
    "                elif node.state==batchmodels.ComputeNodeState.start_task_failed:\n",
    "                    failed_nodes+=1\n",
    "                elif node.state==batchmodels.ComputeNodeState.idle:\n",
    "                    idle_nodes+=1\n",
    "                elif node.state==batchmodels.ComputeNodeState.unusable:\n",
    "                    unusable_nodes+=1\n",
    "            print(' *', starting_nodes, \"starting nodes -\",\n",
    "                  waiting_nodes, \"waiting-for-start-task nodes -\",\n",
    "                  running_nodes, \"running nodes -\",\n",
    "                  failed_nodes, \"failed nodes -\",\n",
    "                  unusable_nodes, \"unusable nodes -\",\n",
    "                  idle_nodes, \"idle nodes\")\n",
    "            if (running_nodes+failed_nodes+idle_nodes+unusable_nodes)>=mypool.current_dedicated_nodes:\n",
    "                print('Pool', pool_id, 'is ready')\n",
    "                return\n",
    "        time.sleep(30)\n",
    "\n",
    "    raise TimeoutError(\"Timed out waiting for pool to be deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pool status and wait until it does not exist\n",
    "def wait_for_pool_to_be_deleted(pool_id):\n",
    "    timeout=datetime.timedelta(minutes=10)\n",
    "    time_to_timeout_at = datetime.datetime.now() + timeout\n",
    "    print(\"Checking status for pool\", pool_id, \"...\")\n",
    "    while datetime.datetime.now() < time_to_timeout_at:\n",
    "        pools = batch_client.pool.list()\n",
    "        poolExists=False\n",
    "        for pool in pools:\n",
    "            if pool.id == pool_id:\n",
    "                poolExists=True\n",
    "                mypool = batch_client.pool.get(pool_id=pool_id)\n",
    "                print(\"Status for pool\", pool_id, \"->\", mypool.state)\n",
    "        if not poolExists:\n",
    "            print('Pool', pool_id, \"does not exist\")\n",
    "            break\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job and Task Creation\n",
    "\n",
    "These functions help with the creation of a job and task:\n",
    "\n",
    "* First, `container_enabled_pool` helps detecting whether a pool is container-enabled or not. The reason is because container-enabled pools only support container-based tasks.\n",
    "* `submit_job_and_add_bash_task` creates a job with an unique name and a bash-based task inside of that job. Only works in non-container-enabled pools\n",
    "* `submit_job_and_add_container_task` creates a job with an unique name and a bash-based task inside of that job. Only works in container-enabled pools\n",
    "* `generate_unique_resource_name` is used to generate an unique ID for the job ID, which uses the current date and time as parts of the name\n",
    "* `print_task_output` will print stderr and stdout from a provided list of task IDs, uses `read_task_file_as_string`\n",
    "* `print_startup_task_output` will print stderr and stdout for the startup task of a given compute node ID, uses `read_node_file_as_string`\n",
    "* Both leverage the function `_read_stream_as_string` to stream the contents of a file in a compute node to the output of the jupyter notebook\n",
    "* `wait_for_tasks_to_complete` waits until all tasks have the status of complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns true if the pool has containerSettings defined\n",
    "# Bash-tasks cannot run on container-enabled pools,\n",
    "#   they give the error \"Task failed \"Container-enabled compute node requires task container settings\"\n",
    "def container_enabled_pool(pool_id):\n",
    "    mypool = batch_client.pool.get(pool_id=pool_id)\n",
    "    try:\n",
    "        containerConfig=mypool.virtual_machine_configuration.container_configuration\n",
    "        if containerConfig.type == 'docker':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create job and task with a bash command\n",
    "def submit_job_and_add_bash_task(batch_client, block_blob_client, job_id, pool_id, command_list):\n",
    "    \"\"\"Submits a job to the Azure Batch service and adds\n",
    "    a task that runs a python script.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param block_blob_client: The storage block blob client to use.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str job_id: The id of the job to create.\n",
    "    :param str pool_id: The id of the pool to use.\n",
    "    \"\"\"\n",
    "    # Add job to pool\n",
    "    print('Adding job...')\n",
    "    job = batchmodels.JobAddParameter(\n",
    "        id=job_id,\n",
    "        pool_info=batchmodels.PoolInformation(pool_id=pool_id))\n",
    "    batch_client.job.add(job)\n",
    "    # Create a blob container, upload a file, and add a SAS\n",
    "    print('Creating storage container {0}...'.format(task_blob_container_name))\n",
    "    block_blob_client.create_container(\n",
    "        task_blob_container_name,\n",
    "        fail_on_exist=False)\n",
    "    sas_url = upload_blob_and_create_sas(\n",
    "        block_blob_client,\n",
    "        task_blob_container_name,\n",
    "        task_file_to_upload,\n",
    "        task_file_to_upload_path,\n",
    "        datetime.datetime.utcnow() + datetime.timedelta(hours=1))\n",
    "    print('Creating bash task')\n",
    "    task = batchmodels.TaskAddParameter(\n",
    "        id=batch_bash_task_name,\n",
    "        command_line=wrap_commands_in_shell('linux', command_list))\n",
    "        #resource_files=[batchmodels.ResourceFile(file_path=task_file_to_upload_path, blob_source=sas_url)])\n",
    "    batch_client.task.add(job_id=job.id, task=task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job/Task creation\n",
    "\n",
    "Creates a container task with different container settings\n",
    "\n",
    "### Features\n",
    "\n",
    "* Can run multiple commands at once\n",
    "* Can override default Batch settings back to the default container settings, such as CMD or WORKDIR\n",
    "* Can upload to the task working dir specific files stored in blob storage\n",
    "\n",
    "### Problems\n",
    "\n",
    "* The -v flag does not seem to work with blobfuse mounts, maybe due to the 770 permissions that blobfuse configures. Maybe trying with this would help? https://docs.microsoft.com/en-us/python/api/azure-batch/azure.batch.models.outputfileblobcontainerdestination?view=azure-python\n",
    "\n",
    "### To Do\n",
    "\n",
    "* Test this: https://docs.microsoft.com/en-us/python/api/azure-batch/azure.batch.models.outputfileblobcontainerdestination?view=azure-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create task with a Docker container (requires a container-enabled pool)\n",
    "def submit_job_and_add_container_task(batch_client, block_blob_client, job_id, pool_id, command_list):\n",
    "    \"\"\"Submits a job to the Azure Batch service and adds\n",
    "    a task that runs a python script.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param block_blob_client: The storage block blob client to use.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str job_id: The id of the job to create.\n",
    "    :param str pool_id: The id of the pool to use.\n",
    "    \"\"\"\n",
    "    # Add job to pool\n",
    "    print('Adding job...')\n",
    "    job = batchmodels.JobAddParameter(\n",
    "        id=job_id,\n",
    "        pool_info=batchmodels.PoolInformation(pool_id=pool_id))\n",
    "    batch_client.job.add(job)\n",
    "    # Create a blob container, upload a file, and add a SAS\n",
    "    print('Creating storage container {0}...'.format(task_blob_container_name))\n",
    "    block_blob_client.create_container(\n",
    "        task_blob_container_name,\n",
    "        fail_on_exist=False)\n",
    "    sas_url = upload_blob_and_create_sas(\n",
    "        block_blob_client,\n",
    "        task_blob_container_name,\n",
    "        task_file_to_upload,\n",
    "        task_file_to_upload_path,\n",
    "        datetime.datetime.utcnow() + datetime.timedelta(hours=1))\n",
    "    # Explicitly allow for an empty command list, in which case the default container CMD would be run\n",
    "    if len(command_list)>0:\n",
    "        command = wrap_commands_in_shell('linux', command_list)\n",
    "    else:\n",
    "        command = ''\n",
    "    # Define container settings for the task (note that the registry name is all lower case!!!!)\n",
    "    task_container_settings = batch.models.TaskContainerSettings(\n",
    "        image_name=docker_image_name.lower(), \n",
    "        #container_run_options='--rm --workdir=\"\"')\n",
    "        container_run_options='-v /mnt/blobdrive:/mnt/blobdrive:ro')\n",
    "        #container_run_options='--rm')\n",
    "    # Add a container-type task with the previous settings\n",
    "    print('Creating task with Docker image {0}...'.format(docker_image_name.lower()))\n",
    "    task = batch.models.TaskAddParameter(\n",
    "        id=batch_task_name,\n",
    "        command_line=command,\n",
    "        container_settings=task_container_settings)\n",
    "    batch_client.task.add(job_id=job.id, task=task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stdout and stderr files from a given task list\n",
    "def print_task_output(batch_client, job_id, task_ids, encoding=None):\n",
    "    \"\"\"Prints the stdout and stderr for each task specified.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param str job_id: The id of the job to monitor.\n",
    "    :param task_ids: The collection of tasks to print the output for.\n",
    "    :type task_ids: `list`\n",
    "    :param str encoding: The encoding to use when downloading the file.\n",
    "    \"\"\"\n",
    "    for task_id in task_ids:\n",
    "        #stdout\n",
    "        try:\n",
    "            file_text = read_task_file_as_string(\n",
    "                batch_client,\n",
    "                job_id,\n",
    "                task_id,\n",
    "                stdout_filename,\n",
    "                encoding)\n",
    "\n",
    "            print(\"{} content for task {}: \".format(stdout_filename, task_id))\n",
    "            print(file_text)\n",
    "        except:\n",
    "            print('I could not find stdout file', stdout_filename, 'for task', task_id)\n",
    "        #stderr\n",
    "        try:\n",
    "            file_text = read_task_file_as_string(\n",
    "                batch_client,\n",
    "                job_id,\n",
    "                task_id,\n",
    "                stderr_filename,\n",
    "                encoding)\n",
    "            print(\"{} content for task {}: \".format(\n",
    "                stderr_filename,\n",
    "                task_id))\n",
    "            print(file_text)\n",
    "        except:\n",
    "            print('I could not find stderr file', stderr_filename, 'for task', task_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stdout and stderr for the startup task of a compute node\n",
    "# It seems that sometimes it cannot find one or both of the files, for some reason\n",
    "def print_startup_task_output(batch_client, node_id, encoding=None):\n",
    "    \"\"\"Prints the stdout and stderr for the startup task of each specified node.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param str job_id: The id of the job to monitor.\n",
    "    :param task_ids: The collection of tasks to print the output for.\n",
    "    :type task_ids: `list`\n",
    "    :param str encoding: The encoding to use when downloading the file.\n",
    "    \"\"\"\n",
    "    #stdout\n",
    "    task_stdout_filename=os.path.join('startup', stdout_filename)\n",
    "    task_stderr_filename=os.path.join('startup', stderr_filename)\n",
    "    try:\n",
    "        file_text = read_node_file_as_string(\n",
    "            batch_client,\n",
    "            node_id,\n",
    "            task_stdout_filename,\n",
    "            encoding)\n",
    "\n",
    "        print(\"{} content for startup task in node {}: \".format(task_stdout_filename, node_id))\n",
    "        print(file_text)\n",
    "    except:\n",
    "        print('I could not find stdout file', task_stdout_filename, 'for startup task in node', node_id)\n",
    "    #stderr\n",
    "    try:\n",
    "        file_text = read_node_file_as_string(\n",
    "            batch_client,\n",
    "            node_id,\n",
    "            task_stderr_filename,\n",
    "            encoding)\n",
    "        print(\"{} content for startup task in node {}: \".format(task_stderr_filename, task_id))\n",
    "        print(file_text)\n",
    "    except:\n",
    "        print('I could not find stderr file', task_stderr_filename, 'for startup task in node', node_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a file from a task and return a stream\n",
    "def read_task_file_as_string(\n",
    "    batch_client, job_id, task_id, file_name, encoding=None):\n",
    "    \"\"\"Reads the specified file as a string.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param str job_id: The id of the job.\n",
    "    :param str task_id: The id of the task.\n",
    "    :param str file_name: The name of the file to read.\n",
    "    :param str encoding: The encoding of the file. The default is utf-8.\n",
    "    :return: The file content.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    stream = batch_client.file.get_from_task(job_id, task_id, file_name)\n",
    "    return _read_stream_as_string(stream, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a file from a compute node and return a stream\n",
    "def read_node_file_as_string(\n",
    "    batch_client, node_id, file_name, encoding=None):\n",
    "    \"\"\"Reads the specified file as a string.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param str job_id: The id of the job.\n",
    "    :param str task_id: The id of the task.\n",
    "    :param str file_name: The name of the file to read.\n",
    "    :param str encoding: The encoding of the file. The default is utf-8.\n",
    "    :return: The file content.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    stream = batch_client.file.get_from_compute_node(pool_id, node_id, file_name)\n",
    "    return _read_stream_as_string(stream, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file stream, this function is used by read_task_file_as_string and read_node_file_as_string\n",
    "def _read_stream_as_string(stream, encoding):\n",
    "    \"\"\"Read stream as string\n",
    "    :param stream: input stream generator\n",
    "    :param str encoding: The encoding of the file. The default is utf-8.\n",
    "    :return: The file content.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    output = io.BytesIO()\n",
    "    try:\n",
    "        for data in stream:\n",
    "            output.write(data)\n",
    "        if encoding is None:\n",
    "            encoding = 'utf-8'\n",
    "        return output.getvalue().decode(encoding)\n",
    "    finally:\n",
    "        output.close()\n",
    "    raise RuntimeError('could not write data to stream or decode bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until all tasks have the status TaskState.completed\n",
    "def wait_for_tasks_to_complete(batch_client, job_id, timeout):\n",
    "    \"\"\"Waits for all the tasks in a particular job to complete.\n",
    "    :param batch_client: The batch client to use.\n",
    "    :type batch_client: `batchserviceclient.BatchServiceClient`\n",
    "    :param str job_id: The id of the job to monitor.\n",
    "    :param timeout: The maximum amount of time to wait.\n",
    "    :type timeout: `datetime.timedelta`\n",
    "    \"\"\"\n",
    "    time_to_timeout_at = datetime.datetime.now() + timeout\n",
    "\n",
    "    while datetime.datetime.now() < time_to_timeout_at:\n",
    "        print(\"Checking if all tasks are complete...\")\n",
    "        tasks = batch_client.task.list(job_id)\n",
    "        incomplete_tasks = [task for task in tasks if\n",
    "                            task.state != batchmodels.TaskState.completed]\n",
    "        if not incomplete_tasks:\n",
    "            return\n",
    "        time.sleep(10)\n",
    "    raise TimeoutError(\"Timed out waiting for tasks to complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create unique job IDs\n",
    "def generate_unique_resource_name(resource_prefix):\n",
    "    \"\"\"Generates a unique resource name by appending a time\n",
    "    string after the specified prefix.\n",
    "    :param str resource_prefix: The resource prefix to use.\n",
    "    :return: A string with the format \"resource_prefix-<time>\".\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    return resource_prefix + \"-\" + \\\n",
    "        datetime.datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "This is the main routine, that comprises three steps:\n",
    "1. Pool creation\n",
    "2. Job/task creation (only container-based tasks will work on a container-enabled pool)\n",
    "3. Cleanup, either using some conditional variables or unconditionally (to be sure that no resources persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a batch client, that will be used throughout the rest of the notebook to operate Azure Batch\n",
    "print(\"Creating Azure Batch client...\")\n",
    "credentials = batchauth.SharedKeyCredentials(\n",
    "    batch_account_name,\n",
    "    batch_account_key)\n",
    "batch_client = batch.BatchServiceClient(\n",
    "    credentials,\n",
    "    base_url=batch_service_url)\n",
    "# Retry 5 times -- default is 3\n",
    "batch_client.config.retry_policy.retries = 5\n",
    "\n",
    "print(\"Creating Azure Storage client...\")\n",
    "block_blob_client = azureblob.BlockBlobService(\n",
    "    account_name=storage_account_name,\n",
    "    account_key=storage_account_key,\n",
    "    endpoint_suffix=storage_account_suffix)\n",
    "\n",
    "print (\"Clients created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create container-based pool\n",
    "pool_id = batch_pool_name\n",
    "print(\"Creating Azure Batch pool\", pool_id, \"for Docker containers...\")\n",
    "create_container_pool(\n",
    "    batch_client,\n",
    "    block_blob_client,\n",
    "    pool_id,\n",
    "    pool_vm_size,\n",
    "    pool_vm_count)\n",
    "wait_for_pool_to_complete(batch_client, pool_id, datetime.timedelta(minutes=10))\n",
    "print_pool_info(pool_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Container-based task (only works for container-enabled pools)\n",
    "# Learnings:\n",
    "# - Tasks run per default under the user '_azbatch', and have access to each other's files\n",
    "# - Tasks run in the working dir '/mnt/batch/tasks/workitems/{job_id}/job-1/{task_id}/wd'\n",
    "# - The directory /mnt/batch is mounted in the container automatically by Azure Batch\n",
    "if container_enabled_pool(pool_id):   \n",
    "    command_list = ['pwd', 'whoami', 'ls -al /mnt/', 'ls -al /mnt/blobdrive', 'echo hello >/mnt/blobdrive/helloworld.txt']\n",
    "    job_id = generate_unique_resource_name(batch_job_name)\n",
    "    print('Submitting Azure Batch job', job_id, '- Command list is ->', command_list)\n",
    "    submit_job_and_add_container_task(\n",
    "        batch_client,\n",
    "        block_blob_client,\n",
    "        job_id, pool_id, command_list)\n",
    "    print(\"Waiting for tasks to complete...\")\n",
    "    wait_for_tasks_to_complete(\n",
    "        batch_client,\n",
    "        job_id,\n",
    "        datetime.timedelta(minutes=25))\n",
    "    tasks = batch_client.task.list(job_id)\n",
    "    task_ids = [task.id for task in tasks]\n",
    "    print_task_output(batch_client, job_id, task_ids)\n",
    "else:\n",
    "    print('Container tasks can only run on container-enabled pools, but {0} does not seem to have a container configuration'.format(pool_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker settings in a container-enabled task\n",
    "\n",
    "Here you can see some the output (truncated for readability) of the docker inspect <container_name> for a container-enabled task:\n",
    "\n",
    "Notice the following:\n",
    "\n",
    "* Host binds: all of /mnt/batch/tasks (RW, including other tasks' files), /etc/passwd (RO), /etc/group (RO), /etc/sudoers (RO)\n",
    "* You can add additional volumes with the Docker -v option when launching the task. See here for more info: https://docs.docker.com/storage/bind-mounts/ \n",
    "* Env variables\n",
    "* Working dir (you can override it with specific container settings in the task, if you want to use the default container wd)\n",
    "* Command (you can override it with specific container settings in the task, if you want to use the default container CMD)\n",
    "* Networking is the default Docker networking\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"Id\": \"906199ee65d7fa7ae36c2213a5f2d4817cd3abb2132fb9a6882b5ceec2095d7e\",\n",
    "        \"Created\": \"2018-07-25T07:45:45.613969371Z\",\n",
    "        \"Path\": \"/bin/bash\",\n",
    "        \"Args\": [\n",
    "            \"-c\",\n",
    "            \"set -e; set -o pipefail; pwd;whoami >./whoami.txt;ls /mnt/;sleep 300; wait\"\n",
    "        ],\n",
    "        \"Image\": \"sha256:f4b156f12e76a7e364de18c8869131a36cd562dba984ccee47d84c121d16c7a9\",\n",
    "        \"ResolvConfPath\": \"/mnt/docker/containers/906199ee65d7fa7ae36c2213a5f2d4817cd3abb2132fb9a6882b5ceec2095d7e/resolv.conf\",\n",
    "        \"HostnamePath\": \"/mnt/docker/containers/906199ee65d7fa7ae36c2213a5f2d4817cd3abb2132fb9a6882b5ceec2095d7e/hostname\",\n",
    "        \"HostsPath\": \"/mnt/docker/containers/906199ee65d7fa7ae36c2213a5f2d4817cd3abb2132fb9a6882b5ceec2095d7e/hosts\",\n",
    "        \"Driver\": \"overlay2\",\n",
    "        \"Platform\": \"linux\",\n",
    "        \"MountLabel\": \"\",\n",
    "        \"ProcessLabel\": \"\",\n",
    "        \"AppArmorProfile\": \"docker-default\",\n",
    "        \"HostConfig\": {\n",
    "            \"Binds\": [\n",
    "                \"/mnt/batch/tasks:/mnt/batch/tasks:rw\",\n",
    "                \"/etc/passwd:/etc/passwd:ro\",\n",
    "                \"/etc/group:/etc/group:ro\",\n",
    "                \"/etc/sudoers:/etc/sudoers:ro\"\n",
    "            ],\n",
    "        },\n",
    "        \"Mounts\": [\n",
    "            {\n",
    "                \"Type\": \"bind\",\n",
    "                \"Source\": \"/mnt/batch/tasks\",\n",
    "                \"Destination\": \"/mnt/batch/tasks\",\n",
    "                \"Mode\": \"rw\",\n",
    "                \"RW\": true,\n",
    "                \"Propagation\": \"rprivate\"\n",
    "            },\n",
    "            {\n",
    "                \"Type\": \"bind\",\n",
    "                \"Source\": \"/etc/passwd\",\n",
    "                \"Destination\": \"/etc/passwd\",\n",
    "                \"Mode\": \"ro\",\n",
    "                \"RW\": false,\n",
    "                \"Propagation\": \"rprivate\"\n",
    "            },\n",
    "            {\n",
    "                \"Type\": \"bind\",\n",
    "                \"Source\": \"/etc/group\",\n",
    "                \"Destination\": \"/etc/group\",\n",
    "                \"Mode\": \"ro\",\n",
    "                \"RW\": false,\n",
    "                \"Propagation\": \"rprivate\"\n",
    "            },\n",
    "            {\n",
    "                \"Type\": \"bind\",\n",
    "                \"Source\": \"/etc/sudoers\",\n",
    "                \"Destination\": \"/etc/sudoers\",\n",
    "                \"Mode\": \"ro\",\n",
    "                \"RW\": false,\n",
    "                \"Propagation\": \"rprivate\"\n",
    "            }\n",
    "        ],\n",
    "        \"Config\": {\n",
    "            \"Hostname\": \"906199ee65d7\",\n",
    "            \"Domainname\": \"\",\n",
    "            \"User\": \"1000:1000\",\n",
    "            \"AttachStdin\": false,\n",
    "            \"AttachStdout\": true,\n",
    "            \"AttachStderr\": true,\n",
    "            \"Tty\": false,\n",
    "            \"OpenStdin\": false,\n",
    "            \"StdinOnce\": false,\n",
    "            \"Env\": [\n",
    "                \"AZ_BATCH_NODE_SHARED_DIR=/mnt/batch/tasks/shared\",\n",
    "                \"AZ_BATCH_ACCOUNT_NAME=batcherjosito\",\n",
    "                \"AZ_BATCH_TASK_USER_IDENTITY=PoolNonAdmin\",\n",
    "                \"AZ_BATCH_JOB_ID=myJob-20180725-074543\",\n",
    "                \"AZ_BATCH_TASK_USER=_azbatch\",\n",
    "                \"AZ_BATCH_TASK_WORKING_DIR=/mnt/batch/tasks/workitems/myJob-20180725-074543/job-1/myDockerTask/wd\",\n",
    "                \"AZ_BATCH_POOL_ID=mycomputepool\",\n",
    "                \"AZ_BATCH_NODE_ID=tvm-2803204300_1-20180725t062808z\",\n",
    "                \"AZ_BATCH_TASK_ID=myDockerTask\",\n",
    "                \"AZ_BATCH_ACCOUNT_URL=https://batcherjosito.westeurope.batch.azure.com/\",\n",
    "                \"AZ_BATCH_NODE_STARTUP_DIR=/mnt/batch/tasks/startup\",\n",
    "                \"AZ_BATCH_CERTIFICATES_DIR=/mnt/batch/tasks/workitems/myJob-20180725-074543/job-1/myDockerTask/certs\",\n",
    "                \"AZ_BATCH_TASK_DIR=/mnt/batch/tasks/workitems/myJob-20180725-074543/job-1/myDockerTask\",\n",
    "                \"AZ_BATCH_NODE_IS_DEDICATED=true\",\n",
    "                \"AZ_BATCH_NODE_ROOT_DIR=/mnt/batch/tasks\",            \n",
    "                \"PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
    "                \"LANG=C.UTF-8\",\n",
    "                \"GPG_KEY=0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\",\n",
    "                \"PYTHON_VERSION=3.7.0\",\n",
    "                \"PYTHON_PIP_VERSION=10.0.1\"\n",
    "            ],\n",
    "            \"Cmd\": [\n",
    "                \"/bin/bash\",\n",
    "                \"-c\",\n",
    "                \"set -e; set -o pipefail; pwd;whoami >./whoami.txt;ls /mnt/;sleep 300; wait\"\n",
    "            ],\n",
    "            \"Image\": \"erjositoacr.azurecr.io/helloworld:2.1\",\n",
    "            \"Volumes\": {\n",
    "                \"/etc/group\": {},\n",
    "                \"/etc/passwd\": {},\n",
    "                \"/etc/sudoers\": {},\n",
    "                \"/mnt/batch/tasks\": {}\n",
    "            },\n",
    "            \"WorkingDir\": \"/mnt/batch/tasks/workitems/myJob-20180725-074543/job-1/myDockerTask/wd\",\n",
    "            \"Entrypoint\": null,\n",
    "            \"OnBuild\": null,\n",
    "            \"Labels\": {\n",
    "                \"batchtaskid\": \"batcherjosito 22F442DAB2831FFB$myjob-20180725-074543 22F43673538A9979$job-1$mydockertask$0\"\n",
    "            }\n",
    "        },\n",
    "        \"NetworkSettings\": {\n",
    "            \"Bridge\": \"\",\n",
    "            \"SandboxID\": \"839d9da52100d83269df1f241d05d1e90d50f3bf0cb2980a007a315d44a932dd\",\n",
    "            \"HairpinMode\": false,\n",
    "            \"LinkLocalIPv6Address\": \"\",\n",
    "            \"LinkLocalIPv6PrefixLen\": 0,\n",
    "            \"Ports\": {},\n",
    "            \"SandboxKey\": \"/var/run/docker/netns/839d9da52100\",\n",
    "            \"SecondaryIPAddresses\": null,\n",
    "            \"SecondaryIPv6Addresses\": null,\n",
    "            \"EndpointID\": \"9a9d9ee42dfd804334c2fe6622d7d70b75010c84e3c57dad5cee31b707baabc0\",\n",
    "            \"Gateway\": \"172.17.0.1\",\n",
    "            \"GlobalIPv6Address\": \"\",\n",
    "            \"GlobalIPv6PrefixLen\": 0,\n",
    "            \"IPAddress\": \"172.17.0.2\",\n",
    "            \"IPPrefixLen\": 16,\n",
    "            \"IPv6Gateway\": \"\",\n",
    "            \"MacAddress\": \"02:42:ac:11:00:02\",\n",
    "            \"Networks\": {\n",
    "                \"bridge\": {\n",
    "                    \"IPAMConfig\": null,\n",
    "                    \"Links\": null,\n",
    "                    \"Aliases\": null,\n",
    "                    \"NetworkID\": \"f8a3cc56b2f72abad3ab24fc2a5a5c70db03efe47ddb39ba1fc473ac457a3faf\",\n",
    "                    \"EndpointID\": \"9a9d9ee42dfd804334c2fe6622d7d70b75010c84e3c57dad5cee31b707baabc0\",\n",
    "                    \"Gateway\": \"172.17.0.1\",\n",
    "                    \"IPAddress\": \"172.17.0.2\",\n",
    "                    \"IPPrefixLen\": 16,\n",
    "                    \"IPv6Gateway\": \"\",\n",
    "                    \"GlobalIPv6Address\": \"\",\n",
    "                    \"GlobalIPv6PrefixLen\": 0,\n",
    "                    \"MacAddress\": \"02:42:ac:11:00:02\",\n",
    "                    \"DriverOpts\": null\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bash-based task (only works for non-container-enabled pools)\n",
    "if not container_enabled_pool(pool_id):\n",
    "    command_line_list= ['printenv >./printenv.txt', 'whoami >./whoami.txt', 'ls -a $AZ_BATCH_TASK_WORKING_DIR/*']\n",
    "    print('Submitting Azure Batch job with bash commands')\n",
    "    job_id = generate_unique_resource_name(batch_job_name)\n",
    "    submit_job_and_add_bash_task(batch_client, block_blob_client, job_id, pool_id, command_line_list)\n",
    "    print(\"Waiting for tasks to complete...\")\n",
    "    wait_for_tasks_to_complete(\n",
    "        batch_client,\n",
    "        job_id,\n",
    "        datetime.timedelta(minutes=25))\n",
    "    tasks = batch_client.task.list(job_id)\n",
    "    task_ids = [task.id for task in tasks]\n",
    "    print_task_output(batch_client, job_id, task_ids)\n",
    "else:\n",
    "    print('Bash tasks cannot run on container-enabled pools, {0} seems to have a container configuration'.format(pool_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional clean up\n",
    "if should_delete_container:\n",
    "    block_blob_client.delete_container(blob_container_name, fail_not_exist=False)\n",
    "if should_delete_job:\n",
    "    print(\"Deleting job: \", job_id)\n",
    "    batch_client.job.delete(job_id)\n",
    "if should_delete_pool:\n",
    "    print(\"Deleting pool: \", pool_id)\n",
    "    batch_client.pool.delete(pool_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconditional cleanup\n",
    "\n",
    "Do this to stop all costs (delete the pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional clean up\n",
    "# Blob storage\n",
    "print('Deleting blob containers', startup_blob_container_name, 'and', task_blob_container_name)\n",
    "block_blob_client.delete_container(startup_blob_container_name, fail_not_exist=False)\n",
    "block_blob_client.delete_container(task_blob_container_name, fail_not_exist=False)\n",
    "# Delete job, if it exists\n",
    "print(\"Deleting jobs\")\n",
    "jobs = batch_client.job.list()\n",
    "try:\n",
    "    for job in jobs: \n",
    "        if job.id == job_id:\n",
    "            print(\"Deleting batch job\", job_id)\n",
    "            batch_client.job.delete(job_id)\n",
    "# If the try block does not work, it is probably because the variable job_id does not exist\n",
    "except:\n",
    "    print('  * Looks like there were no jobs to delete')\n",
    "# Delete pool\n",
    "print(\"Deleting batch pool\", pool_id)\n",
    "try:\n",
    "    batch_client.pool.delete(pool_id)\n",
    "    wait_for_pool_to_be_deleted(pool_id)\n",
    "except:\n",
    "    print('  * Looks like the pool', pool_id, 'does not exist any more')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
